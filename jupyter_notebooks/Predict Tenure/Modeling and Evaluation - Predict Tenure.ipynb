{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Modeling and Evaluation - Predict Tenure.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Fit and evaluate a regression model to predict tenure levels for a prospect that will likely churn\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/TelcoCustomerChurn.csv\n",
        "* instructions on which variables to use for data cleaning and feature engineering. They are found on its respectives notebooks.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Train set (features and target)\n",
        "* Test set (features and target)\n",
        "* ML pipeline to predict tenure\n",
        "* labels map\n",
        "* Feature Importance Plot\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbuGQj9lDAEo"
      },
      "source": [
        "# Install and Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAx1yVscyB3M"
      },
      "source": [
        "* You eventually will need to restart runtime when installing packages, please note cell output when installing a package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsBfLDnhx-2k"
      },
      "source": [
        "! pip install feature-engine==1.0.2\n",
        "! pip install scikit-learn==0.24.2\n",
        "! pip install xgboost==1.2.1\n",
        "\n",
        "# Code for restarting the runtime, that will restart colab session\n",
        "# It is a good practice after you install a package in a colab session\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUFuYskeybZL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0QdOnpiUTRC"
      },
      "source": [
        "# Setup GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIifw4yCpZwI"
      },
      "source": [
        "* Go to Edit → Notebook Settings\n",
        "* In the Hardware accelerator menu, selects GPU\n",
        "* note: when you select an option, either GPU, TPU or None, you switch among kernels/sessions\n",
        "\n",
        "---\n",
        "* How to know if I am using the GPU?\n",
        "  * run the code below, if the output is different than '0' or null/nothing, you are using GPU in this session\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHJJd1XhUTjd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgHiVgPviuMx"
      },
      "source": [
        "# **Connection between: Colab Session and your GitHub Repo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtPQ7EnPiuMy"
      },
      "source": [
        "### Insert your **credentials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhDHrzxEiuMz"
      },
      "source": [
        "* The variable's content will exist only while the session exists. Once this session terminates, the variable's content will be erased permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye8aYwLkiuMz"
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from IPython.display import clear_output \n",
        "\n",
        "print(\"=== Insert your credentials === \\nType in and hit Enter\")\n",
        "os.environ['UserName'] = getpass('GitHub User Name: ')\n",
        "os.environ['UserEmail'] = getpass('GitHub User E-mail: ')\n",
        "os.environ['RepoName'] = getpass('GitHub Repository Name: ')\n",
        "os.environ['UserPwd'] = getpass('GitHub Account Token: ')\n",
        "clear_output()\n",
        "print(\"* Thanks for inserting your credentials!\")\n",
        "print(f\"* You may now Clone your Repo to this Session, \"\n",
        "      f\"then Connect this Session to your Repo.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JjRkDt1eOAr"
      },
      "source": [
        "* **Credentials format disclaimer**: when opening Jupyter notebooks in Colab that are hosted at GitHub, we ask you to not consider special characters in your **password**, like @ ! \" # $ % & ' ( ) * + , - . / :;< = > ? @ [\\ ]^_ ` { } | ~\n",
        "  * Otherwise it will not work properly the git push command, since the credentials are concatenated in the command: username:password@github.com/username/repo , the git push command will not work properly when these terms have special characters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_amd2ygiuM0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I2eQe-YiuM0"
      },
      "source": [
        "### **Clone** your GitHub Repo to your current Colab session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfD0o1u1iuM0"
      },
      "source": [
        "* So you can have access to your project's files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGOPTqcmiuM1"
      },
      "source": [
        "! git clone https://github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "! rm -rf sample_data   # remove content/sample_data folder, since we dont need it for this project\n",
        "\n",
        "import os\n",
        "if os.path.isdir(os.environ['RepoName']):\n",
        "  print(\"\\n\")\n",
        "  %cd /content/{os.environ['RepoName']}\n",
        "  print(f\"\\n\\n* Current session directory is:{os.getcwd()}\")\n",
        "  print(f\"* You may refresh the session folder to access {os.environ['RepoName']} folder.\")\n",
        "else:\n",
        "  print(f\"\\n* The Repo {os.environ['UserName']}/{os.environ['RepoName']} was not cloned.\"\n",
        "        f\" Please check your Credentials: UserName and RepoName\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uhzcFjeiuM1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS3yEKFJiuM1"
      },
      "source": [
        "### **Connect** this Colab session to your GitHub Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_tFmsYgiuM2"
      },
      "source": [
        "* So if you need, you can push files generated in this session to your Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CveMisgfiuM2"
      },
      "source": [
        "! git config --global user.email {os.environ['UserEmail']}\n",
        "! git config --global user.name {os.environ['UserName']}\n",
        "! git remote rm origin\n",
        "! git remote add origin https://{os.environ['UserName']}:{os.environ['UserPwd']}@github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "\n",
        "# the logic is: create a temporary file in the session, pushes it to the repo. Delete this file, update the repo\n",
        "# If it works, it is a signed that the session is connected to the repo.\n",
        "import uuid\n",
        "file_name = \"session_connection_test_\" + str(uuid.uuid4()) # generates a unique file name\n",
        "with open(f\"{file_name}.txt\", \"w\") as file: file.write(\"text\")\n",
        "print(\"=== Testing Session Connectivity to the Repo === \\n\")\n",
        "! git add . ; ! git commit -m {file_name + \"_added_file\"} ; ! git push origin main \n",
        "print(\"\\n\\n\")\n",
        "os.remove(f\"{file_name}.txt\")\n",
        "! git add . ; ! git commit -m {file_name + \"_removed_file\"}; ! git push origin main\n",
        "\n",
        "# delete your Credentials (username and password)\n",
        "os.environ['UserName'] = os.environ['UserPwd'] = os.environ['UserEmail'] = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKKIufOcexSz"
      },
      "source": [
        "* If output above indicates there was a **failure in the authentication**, please insert again your credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXKlJFX0iuM5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data for Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk7DU_ekbtX8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/TelcoCustomerChurn.csv\")\n",
        "      .query(\"Churn == 1\")  # subset churned customer\n",
        "      .drop(labels=['customerID','TotalCharges','Churn'],axis=1)  \n",
        "                    # variables we will not need for this project\n",
        "                    # we will not need Churn, since it is has only 1\n",
        "  )\n",
        "\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krjAk78Tbyhv"
      },
      "source": [
        "# Regressor: Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr9LUaOV08Su"
      },
      "source": [
        "* In the ML Pipeline, we are using the raw data, therefore we need to create the pipeline with data cleaninig and feature engineering steps\n",
        "  * This pipeline will be used in the Train Set, Test Set and Live Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzSg8Iwjl7dz"
      },
      "source": [
        "### ML pipeline for Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MK_AHgh86Sc"
      },
      "source": [
        "Load Estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFUD8ofWl7nm"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "\n",
        "\n",
        "### Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "### ML algorithms \n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge,RidgeCV\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr0kimOaAjL6"
      },
      "source": [
        " Pipeline for Data Cleaning and Feat Eng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6keis6ao8LA"
      },
      "source": [
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "  pipeline_base = Pipeline(\n",
        "      [\n",
        "\n",
        "      (\"OrdinalCategoricalEncoder\",OrdinalEncoder(encoding_method='arbitrary', \n",
        "                                                  variables = [ 'gender', 'Partner', 'Dependents', 'PhoneService',\n",
        "                                                               'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
        "                                                               'OnlineBackup','DeviceProtection', 'TechSupport', \n",
        "                                                               'StreamingTV', 'StreamingMovies','Contract', \n",
        "                                                               'PaperlessBilling', 'PaymentMethod']\n",
        "                                                  )\n",
        "      ),      \n",
        "       \n",
        "\n",
        "      (\"SmartCorrelatedSelection\",SmartCorrelatedSelection(variables=None, method=\"spearman\",\n",
        "                                                           threshold=0.6,selection_method=\"variance\")\n",
        "      ),\n",
        "       \n",
        "    ]\n",
        "  )\n",
        "\n",
        "  return pipeline_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWTrFyxZWVar"
      },
      "source": [
        "## ML Pipeline for Modelling and Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF9V5_ctHbO7"
      },
      "source": [
        "* Pipeline Optmization: Add Feature Scaling, Feature Selection and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8lGTb0yHbZq"
      },
      "source": [
        "def PipelineOptimization(model):\n",
        "  pipe = PipelineDataCleaningAndFeatureEngineering()\n",
        "  pipe.steps.append([\"scaler\", StandardScaler()])\n",
        "  pipe.steps.append([\"feat_selection\", SelectFromModel(model)])\n",
        "  pipe.steps.append([\"model\", model])\n",
        "  \n",
        "  return pipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDmjjF3tHuCU"
      },
      "source": [
        "* Custom Class for hyperparameter Optmization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpTcVDtQ5RMc"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model=  PipelineOptimization(self.models[key])\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns], self.grid_searches\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD6B3CuhiDMT"
      },
      "source": [
        "## Split Train Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpxaylKk-6CQ"
      },
      "source": [
        "Quick recap in our raw dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfKHc63v-6Zm"
      },
      "source": [
        "print(df.shape)\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs6mDnoDhzwj"
      },
      "source": [
        "Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pFzP2iGiIk1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df.drop(['tenure'],axis=1),\n",
        "                                    df['tenure'],\n",
        "                                    test_size=0.2,\n",
        "                                    random_state=0\n",
        "                                    )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j285uIq1f3h3"
      },
      "source": [
        "## Target Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0IYJz0uf2CT"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "def Target_DistributionAndStats(y_train,y_test):\n",
        "\n",
        "  figure, ax = plt.subplots(nrows=1, ncols=2,figsize=(12,3))\n",
        "  sns.histplot(x=y_train, kde=True,ax=ax[0]).set(title='y train')\n",
        "  sns.histplot(x=y_test, kde=True,ax=ax[1]).set(title='y test')\n",
        "  plt.show();\n",
        "\n",
        "  print(\"\\n* Train set - target descriptive stats: \\n\", y_train.describe().to_frame().round(3))\n",
        "  print(f\"\\n* Train set skewness: {y_train.skew().round(3)}, and kurtosis: {y_train.kurt().round(3)} \\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4TsdEhkhlht"
      },
      "source": [
        "Target_DistributionAndStats(y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUSDkpgSnNed"
      },
      "source": [
        "Target Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqTCBJMua4QS"
      },
      "source": [
        "import sklearn.preprocessing\n",
        "target_transformer = sklearn.preprocessing.PowerTransformer(method='box-cox',standardize=True)\n",
        "\n",
        "y_train = target_transformer.fit_transform(y_train.to_frame())\n",
        "y_train = pd.Series(y_train.reshape(-1), name='tenure')\n",
        "\n",
        "y_test = target_transformer.transform(y_test.to_frame())\n",
        "y_test = pd.Series(y_test.reshape(-1), name='tenure')\n",
        "\n",
        "# target_transformer.inverse_transform(y_test.values.reshape(-1,1)) # test for inverse_transform\n",
        "Target_DistributionAndStats(y_train,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-15-sWUST6XX"
      },
      "source": [
        "## Grid Search CV - Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTFXq-ieogBj"
      },
      "source": [
        "### Use standard hyper parameters to find most suitable model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D5u8D_2MvqM"
      },
      "source": [
        "Define models for quick search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZKV86gsPw8c"
      },
      "source": [
        "models_quick_search = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    \"Ridge\": Ridge(random_state=0),\n",
        "    \"RidgeCV\": RidgeCV(),\n",
        "    \"BayesianRidge\": BayesianRidge(),\n",
        "    \"SGDRegressor\": SGDRegressor(random_state=0),\n",
        "    \"ElasticNet\": ElasticNet(random_state=0),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    'LinearRegression': {},\n",
        "    'Ridge': {},\n",
        "    \"RidgeCV\": {},\n",
        "    \"BayesianRidge\": {},\n",
        "    \"SGDRegressor\":{},\n",
        "    \"ElasticNet\": {},\n",
        "    \"DecisionTreeRegressor\": {},\n",
        "    \"RandomForestRegressor\": {},\n",
        "    \"ExtraTreesRegressor\": {},\n",
        "    \"AdaBoostRegressor\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBRegressor\": {},\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGABtSoSLP9u"
      },
      "source": [
        "Do a hyperparameter optmization search "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_q-ru92GiBb"
      },
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7p56nXeoqWo"
      },
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq4YlrmZooiw"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igjPv1kxZ38P"
      },
      "source": [
        "Check best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBzm_jEZ4FD"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pRUAeoG9lrZ"
      },
      "source": [
        "### Do extensive search on most suitable model to find best hyperparameter configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2XCyOYkAYpZ"
      },
      "source": [
        "Define model and parameters, for Extensive Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyjC7ThFAYKY"
      },
      "source": [
        "models_search = {\n",
        "    \"GradientBoostingRegressor\":GradientBoostingRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "# documentation to help on hyperparameter list: \n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
        "\n",
        "# We will not conduct an extensive search, since the focus\n",
        "# is on how to combine all knowledge in an applied project.\n",
        "# In a workplace project, you may spend more time in this step\n",
        "params_search = {\n",
        "    \"GradientBoostingRegressor\":{\n",
        "        'model__n_estimators': [100,300],\n",
        "        'model__learning_rate': [1e-1,1e-2,1e-3], \n",
        "        'model__max_depth': [3,10],\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBy8thxqAlrd"
      },
      "source": [
        "Extensive GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_4Ob7heAYM9"
      },
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtNJJpLEAzdP"
      },
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjauRLNHAYPr"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWryh7BlA2df"
      },
      "source": [
        "Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVWEmpSuA4C7"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_jvnR4sZ8km"
      },
      "source": [
        "Parameters for best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2my-LZFzZ-YD"
      },
      "source": [
        "grid_search_pipelines[best_model].best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgWXlprwaAW-"
      },
      "source": [
        "Define the best regressor, based on search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OZ24jS0aAfP"
      },
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9uT2XmaKISR"
      },
      "source": [
        "## Assess feature importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m6NUUa0KFQX"
      },
      "source": [
        "# after data cleaning and feat engine, the feature space changes\n",
        "columns_after_data_cleaning_feat_eng = (PipelineDataCleaningAndFeatureEngineering()\n",
        "                                        .fit_transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()].to_list()\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "          'Attribute': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
        "          'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
        "  .sort_values(by='Importance', ascending=False)\n",
        "  )\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Attribute'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar',x='Attribute',y='Importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzNyQirSKJj6"
      },
      "source": [
        "## Evaluate Regressor on Train and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye8fsXJYBO1g"
      },
      "source": [
        "Custom Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pBm_vx8BO9s"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error \n",
        "import numpy as np\n",
        "\n",
        "def model_score_train_test_set(X_train, y_train, X_test, y_test,pipeline):\n",
        "\n",
        "\tprint(\"Model Evaluation \\n\")\n",
        "\tprint(\"* Train Set\")\n",
        "\tPredictionEvaluation(X_train,y_train,pipeline)\n",
        "\n",
        "\tprint(\"* Test Set\")\n",
        "\tPredictionEvaluation(X_test,y_test,pipeline)\n",
        "\n",
        "\n",
        "\n",
        "def PredictionEvaluation(X,y,pipeline):\n",
        "  prediction = pipeline.predict(X)\n",
        "\n",
        "  print('R2 Score:', r2_score(y, prediction).round(3))  \n",
        "  print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))  \n",
        "  print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))  \n",
        "  print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y, prediction)).round(3))\n",
        "  print(\"\\n\")\n",
        "\n",
        "  \n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def PredictionVsActual_TrainTestSets(X_train, y_train, X_test, y_test,pipeline):\n",
        "  pred_train = pipeline.predict(X_train)\n",
        "  pred_test = pipeline.predict(X_test)\n",
        "  Plot_Prediction_vs_Actual(y_train,pred_train,y_test, pred_test)\n",
        "\n",
        "\n",
        "\n",
        "def Plot_Prediction_vs_Actual(TrainActual,TrainPred,TestActual,TestPred):\n",
        "\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
        "\n",
        "  sns.scatterplot(x=TrainActual , y=TrainPred, alpha=0.2, ax=axes[0])\n",
        "  sns.lineplot(x=TrainActual , y=TrainActual, color='red', ax=axes[0])\n",
        "  axes[0].set_xlabel(\"Actual\")\n",
        "  axes[0].set_ylabel(\"Predictions\")\n",
        "  axes[0].set_title(\"Train Set\")\n",
        "\n",
        "  sns.scatterplot(x=TestActual , y=TestPred, alpha=0.2, ax=axes[1])\n",
        "  sns.lineplot(x=TestActual , y=TestActual, color='red', ax=axes[1])\n",
        "  axes[1].set_xlabel(\"Actual\")\n",
        "  axes[1].set_ylabel(\"Predictions\")\n",
        "  axes[1].set_title(\"Test Set\")\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV-W5nYyBPdk"
      },
      "source": [
        "Evaluate Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgBgrKJ5KFcX"
      },
      "source": [
        "model_score_train_test_set(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "PredictionVsActual_TrainTestSets(X_train, y_train, X_test, y_test,best_regressor_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ9tjLxEIn3h"
      },
      "source": [
        "# Regressor add PCA() in the pipeline: Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eaMf41ZBhBk"
      },
      "source": [
        "## Rewrite ML Pipeline for Modelling: add PCA step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPWv-kTBKnjR"
      },
      "source": [
        "* It will change only the PipelineOptimization() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfU562GBIsB1"
      },
      "source": [
        "### PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def PipelineOptimization(model):\n",
        "  pipe = PipelineDataCleaningAndFeatureEngineering()\n",
        "  pipe.steps.append([\"PCA\",PCA(n_components=3, random_state=0)])\n",
        "  pipe.steps.append([\"scaler\", StandardScaler()])\n",
        "  pipe.steps.append([\"model\", model])\n",
        "  \n",
        "  return pipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irUsq475Bn7N"
      },
      "source": [
        "## Grid Search CV – Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LVF-KR_Bqum"
      },
      "source": [
        "### Use standard hyper parameters to find most suitable model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XmJNoUcJkKX"
      },
      "source": [
        "models_quick_search = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    \"Ridge\": Ridge(random_state=0),\n",
        "    \"RidgeCV\": RidgeCV(),\n",
        "    \"BayesianRidge\": BayesianRidge(),\n",
        "    \"SGDRegressor\": SGDRegressor(random_state=0),\n",
        "    \"ElasticNet\": ElasticNet(random_state=0),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    'LinearRegression': {},\n",
        "    'Ridge': {},\n",
        "    \"RidgeCV\": {},\n",
        "    \"BayesianRidge\": {},\n",
        "    \"SGDRegressor\":{},\n",
        "    \"ElasticNet\": {},\n",
        "    \"DecisionTreeRegressor\": {},\n",
        "    \"RandomForestRegressor\": {},\n",
        "    \"ExtraTreesRegressor\": {},\n",
        "    \"AdaBoostRegressor\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBRegressor\": {},\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq8td65fJkKY"
      },
      "source": [
        "Do a quick optmization search "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1BdqEB6JkKZ"
      },
      "source": [
        "quick_search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "quick_search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ_Xj5oGJkKZ"
      },
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIC2csxKJkKZ"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3QJ5d7GJkKc"
      },
      "source": [
        "Check best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-qRFydjJkKc"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "383vOhJZBwza"
      },
      "source": [
        "### Do extensive search on most suitable model to find best hyperparameter configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrcbiQHlB9QT"
      },
      "source": [
        "Define model and parameters, for Extensive Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7t-fum6B9QU"
      },
      "source": [
        "models_search = {\n",
        "    \"GradientBoostingRegressor\":GradientBoostingRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "# documentation to help on hyperparameter list: \n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
        "\n",
        "# We will not conduct an extensive search, since the focus\n",
        "# is on how to combine all knowledge in an applied project.\n",
        "# In a workplace project, you may spend more time in this step\n",
        "params_search = {\n",
        "    \"GradientBoostingRegressor\":{\n",
        "        'model__n_estimators': [100,300],\n",
        "        'model__learning_rate': [1e-1,1e-2,1e-3], \n",
        "        'model__max_depth': [3,10],\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvt-IOmHB9QU"
      },
      "source": [
        "Extensive GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXbTwW1UB9QV"
      },
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVUDzRSGB9QV"
      },
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZfOdh5kB9QW"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgoLo5C8B9QW"
      },
      "source": [
        "Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3UGYjpcB9QW"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjY2MdBNB9QX"
      },
      "source": [
        "Parameters for best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uspihv71B9QX"
      },
      "source": [
        "grid_search_pipelines[best_model].best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8HonhniB9QX"
      },
      "source": [
        "Define the best regressor, based on search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC8U4skKB9QY"
      },
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKGmSgINCQwj"
      },
      "source": [
        "## Evaluate Regressor on Train and Tests Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78tt_ZkiJRdE"
      },
      "source": [
        "model_score_train_test_set(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "PredictionVsActual_TrainTestSets(X_train, y_train, X_test, y_test,best_regressor_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwQ5_7rlii-Q"
      },
      "source": [
        "# TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV3gBxwKilA_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK8LJ9AViptX"
      },
      "source": [
        "def CreateTensorFlowModel():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(optimizer='adam',loss='mse')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKAp3TMqranM"
      },
      "source": [
        "# pipeline_before_model =  PipelineDataCleaningAndFeatureEngineering()\n",
        "# X_train_tf = pipeline_before_model.fit_transform(X_train)\n",
        "# X_train_tf = pipeline_before_model.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy_HTrh5i1Pz"
      },
      "source": [
        "model = CreateTensorFlowModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDpunWf6sDkl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp_p_9i4izyP"
      },
      "source": [
        "model.fit(x=X_train_tf,y=y_train.values,\n",
        "          validation_data=(X_train_tf,y_test.values),\n",
        "          epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU_-bkeNi5A8"
      },
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOYpcvuRj8FU"
      },
      "source": [
        "losses.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpKz9qjRUOR0"
      },
      "source": [
        "# Convert Regression to Classification: Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0yf7s9LVZFH"
      },
      "source": [
        "### Convert target to bins and check if it is balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eG5r24uv7JN"
      },
      "source": [
        "Convert numerical continious target to equal frequency bins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzXQjVf-Uoay"
      },
      "source": [
        "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
        "disc = EqualFrequencyDiscretiser(q=3, variables=['tenure'])\n",
        "\n",
        "df_clf = disc.fit_transform(df)\n",
        "df_clf['tenure'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaElij1Wv_gL"
      },
      "source": [
        "Visualize target distribution and range levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-sJMpuVPuR"
      },
      "source": [
        "print(f\"* The classes represent the following ranges: \\n{disc.binner_dict_} \\n\")\n",
        "sns.countplot(data=df_clf, x='tenure')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkPaGZfiXexn"
      },
      "source": [
        "## Rewrite ML Pipeline for Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I53mlfqRUSzn"
      },
      "source": [
        "def PipelineOptimization(model):\n",
        "  pipe = PipelineDataCleaningAndFeatureEngineering()\n",
        "  pipe.steps.append([\"scaler\", StandardScaler()])\n",
        "  pipe.steps.append([\"feat_selection\", SelectFromModel(model)])\n",
        "  pipe.steps.append([\"model\", model])\n",
        "  return pipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW2lu54NCgOC"
      },
      "source": [
        "## Load estimators for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvkMORvOft14"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVnTzZZBC73_"
      },
      "source": [
        "## Split Train Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev5Rb80fC-dP"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df_clf.drop(['tenure'],axis=1),\n",
        "                                    df_clf['tenure'],\n",
        "                                    test_size=0.2,\n",
        "                                    random_state=0\n",
        "                                    )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flZCqIL4DB80"
      },
      "source": [
        "Check if target is balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFLYKem1DCmJ"
      },
      "source": [
        "y_train.value_counts(normalize=True).to_frame().round(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTEEhpvRDF0a"
      },
      "source": [
        "## Grid Seach CV – Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPNNBP-QDIkv"
      },
      "source": [
        "### Use standard hyper parameters to find most suitable model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfW5jSmSe7Gl"
      },
      "source": [
        "models_quick_search = {\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"XGBClassifier\":{},\n",
        "    \"DecisionTreeClassifier\":{},\n",
        "    \"RandomForestClassifier\":{},\n",
        "    \"GradientBoostingClassifier\":{},\n",
        "    \"ExtraTreesClassifier\":{},\n",
        "    \"AdaBoostClassifier\":{},\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDYHs3I1D89F"
      },
      "source": [
        "GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh-nd-JCfX7M"
      },
      "source": [
        "from sklearn.metrics import make_scorer, recall_score\n",
        "quick_search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "quick_search.fit(X_train, y_train,\n",
        "                 scoring = make_scorer(recall_score, pos_label=0, average='micro'),\n",
        "                 n_jobs=-1,cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqQfPBxfEQgf"
      },
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXUbzctLfXd2"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Vs9pB8EVyc"
      },
      "source": [
        "Check best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6R2wXm0XbjG"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQWhAJtcDoSI"
      },
      "source": [
        "### Do extensive search on most suitable model to find best hyperparameter configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyeaZbCFDxf4"
      },
      "source": [
        "Define models and parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxEXnjBWDzOr"
      },
      "source": [
        "models_search = {\n",
        "    \"GradientBoostingClassifier\":GradientBoostingClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "# documentation to help on hyperparameter list: \n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "\n",
        "# We will not conduct an extensive search, since the focus\n",
        "# is on how to combine all knowledge in an applied project.\n",
        "# In a workplace project, you may spend more time in this step\n",
        "params_search = {\n",
        "    \"GradientBoostingClassifier\":{\n",
        "        'model__n_estimators': [100,500],\n",
        "        'model__learning_rate': [1e-1,1e-2,1e-3], \n",
        "        'model__max_depth': [3,10],\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcqabQPpD_vX"
      },
      "source": [
        "Extensive GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC2xgdgkECox"
      },
      "source": [
        "from sklearn.metrics import make_scorer, recall_score\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring = make_scorer(recall_score, pos_label=0, average='micro'),\n",
        "           n_jobs=-1, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDne0BgoEaDz"
      },
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsNiNwdGECra"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bZ2Qu5JEhrp"
      },
      "source": [
        "\n",
        "Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAbJosK8ECt-"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUyqeVjkEjn7"
      },
      "source": [
        "Parameters for best model\n",
        "* We are saving this content for later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXPyDbbxYbv6"
      },
      "source": [
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "best_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YUeAvIsEo5v"
      },
      "source": [
        "Define the best clf pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTrUEOcBYby4"
      },
      "source": [
        "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
        "pipeline_clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGc1W7wEM2GP"
      },
      "source": [
        "## Assess feature importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHN_VRwZarUp"
      },
      "source": [
        "We can assess feature importane for this model with `.feature_importances_`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfckT_bFxFaE"
      },
      "source": [
        "# after data cleaning and feat engine, the feature space changes\n",
        "columns_after_data_cleaning_feat_eng = (PipelineDataCleaningAndFeatureEngineering()\n",
        "                                        .fit_transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "# best_features = columns_after_data_cleaning_feat_eng\n",
        "best_features = columns_after_data_cleaning_feat_eng[pipeline_clf['feat_selection'].get_support()].to_list()\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "          'Attribute': columns_after_data_cleaning_feat_eng[pipeline_clf['feat_selection'].get_support()],\n",
        "          'Importance': pipeline_clf['model'].feature_importances_})\n",
        "  .sort_values(by='Importance', ascending=False)\n",
        "  )\n",
        "\n",
        "best_features = df_feature_importance['Attribute'].to_list() # reassign best features in order\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{best_features}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar',x='Attribute',y='Importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxYUJst9MfR8"
      },
      "source": [
        "best_features_clf = best_features\n",
        "best_features_clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwI6U28UV4C"
      },
      "source": [
        "## Evaluate Classifier on Train and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sL9XamIDTG3"
      },
      "source": [
        "Custom Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMcvrPmdXbmP"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def ClfPredictionEvaluation(X,y,pipeline,LabelsMap):\n",
        "\n",
        "  prediction = pipeline.predict(X)\n",
        "\n",
        "  Map = list() \n",
        "  for key, value in LabelsMap.items():\n",
        "    Map.append( str(key) + \": \" + value)\n",
        "\n",
        "  print('---  Confusion Matrix  ---')\n",
        "  print(pd.DataFrame(confusion_matrix(prediction,y),\n",
        "        columns=[ [\"Actual \" + sub for sub in Map] ], \n",
        "        index = [ [\"Prediction \" + sub for sub in Map ]]\n",
        "        # index=['Prediction 0', 'Prediction 1']\n",
        "        ))\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "  print('---  Classification Report  ---')\n",
        "  print(classification_report(y, prediction),\"\\n\")\n",
        "\n",
        "\n",
        "def ClfPerformanceTrainTestSet(X_train,y_train,X_test,y_test,pipeline,LabelsMap):\n",
        "  print(\"#### Train Set #### \\n\")\n",
        "  ClfPredictionEvaluation(X_train,y_train,pipeline,LabelsMap)\n",
        "\n",
        "  print(\"#### Test Set ####\\n\")\n",
        "  ClfPredictionEvaluation(X_test,y_test,pipeline,LabelsMap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyX8PsH-0z8z"
      },
      "source": [
        "Creates a dictionary that relates the class and numerical interval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGLKOq44xpMw"
      },
      "source": [
        "n_classes = len(disc.binner_dict_['tenure']) - 1\n",
        "classes_ranges = disc.binner_dict_['tenure'][1:-1]\n",
        "\n",
        "labels_map = {}\n",
        "for n in range(0,n_classes):\n",
        "  if n == 0:\n",
        "    labels_map[n] = f\"<{classes_ranges[0]}\"\n",
        "  elif n == n_classes-1:\n",
        "    labels_map[n] = f\"+{classes_ranges[-1]}\"\n",
        "  else:\n",
        "    labels_map[n] = f\"{classes_ranges[n-1]} to {classes_ranges[n]}\"\n",
        "\n",
        "labels_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no7flbMcYbsz"
      },
      "source": [
        "ClfPerformanceTrainTestSet(X_train, y_train ,X_test, y_test,\n",
        "                        pipeline_clf,\n",
        "                        LabelsMap=labels_map )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ3u0TodDdOZ"
      },
      "source": [
        "# Which pipeline to choose?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE5va8Cr-CCy"
      },
      "source": [
        "We fitted multiple pipelines:\n",
        "* Regression\n",
        "* Regression with PCA\n",
        "* Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQR54xeCbIAH"
      },
      "source": [
        "The regressor pipelines didn't reach the expected performance threshold of 0.7 for R2 score, for train and test set.\n",
        "\n",
        "The classifier was tuned on recall for class 0, since we are interested to detect prospects that may churn soon. \n",
        "* It has reasonable performance for class 0 (<4 months) and can separate the opposite classes: class 0 (<4 months) and class 2 (+20 months).\n",
        "* Class 1 (4 to 20 months) has weak performance. We will accept this limitation and will handle a prediction of class 1 as if it was a prediction of class 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BqT1Kne54Fq"
      },
      "source": [
        "# Refit pipeline with best features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpgS-AgU6IWx"
      },
      "source": [
        "## Split Train Test Set, only with best features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_31XFcrg6IWy"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df_clf.drop(['tenure'],axis=1),\n",
        "                                    df_clf['tenure'],\n",
        "                                    test_size=0.2,\n",
        "                                    random_state=0\n",
        "                                    )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohPWfCs2E_3G"
      },
      "source": [
        "Subset Best Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUEIfyLU6IWz"
      },
      "source": [
        "X_train = X_train.filter(best_features_clf)\n",
        "\n",
        "X_test = X_test.filter(best_features_clf)\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsYi88NhFBcx"
      },
      "source": [
        "Check how training data looks like now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vuYQjAfNljQ"
      },
      "source": [
        "X_train.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN4T0UFCE-qy"
      },
      "source": [
        "## Rewrite Data Cleaning and Feature Engineering Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGrvMwV76S1u"
      },
      "source": [
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "  pipeline_base = Pipeline(\n",
        "      [\n",
        "      (\"OrdinalCategoricalEncoder\",OrdinalEncoder(encoding_method='arbitrary', \n",
        "                                                  variables = ['MultipleLines', 'Contract', \n",
        "                                                               'PaymentMethod','Partner']\n",
        "                                                  )\n",
        "      ),\n",
        "       \n",
        "    ]\n",
        "  )\n",
        "\n",
        "  return pipeline_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0O-hHDpFGqd"
      },
      "source": [
        "## Rewrite Modelling Pipeline (removes feat_selection)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGcOyX2y589f"
      },
      "source": [
        "def PipelineOptimization(model):\n",
        "  pipe = PipelineDataCleaningAndFeatureEngineering()\n",
        "  pipe.steps.append([\"scaler\", StandardScaler()])\n",
        "  pipe.steps.append([\"model\", model])\n",
        "  return pipe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fT_mdLWFJFz"
      },
      "source": [
        "## Grid Search CV – Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2l_tUNcFLd0"
      },
      "source": [
        "* using most suitable model from last section and it best hyperparameter configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfKEBTyLeDtj"
      },
      "source": [
        "We are using the same model from the last GridCV search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1qcZktreHH5"
      },
      "source": [
        "models_search"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WaSA9jcecXr"
      },
      "source": [
        "And the best parameters from the last GridCV search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXi0L025eKA6"
      },
      "source": [
        "best_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7jAkvlBeeQl"
      },
      "source": [
        "You will need to type in manually, since the hyperparameter values has to be a list. The previous dictonary is not in this format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9HBXI2E58_5"
      },
      "source": [
        "params_search = {'GradientBoostingClassifier':  {\n",
        "    'model__learning_rate': [0.01],   # the value should be in []\n",
        "    'model__max_depth': [3]}, # the value should be in []\n",
        "    'model__n_estimators': [500] # the value should be in []\n",
        "}\n",
        "params_search"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEZYXLRQfvTL"
      },
      "source": [
        "GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msJPkpo8fFAI"
      },
      "source": [
        "from sklearn.metrics import make_scorer, recall_score\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring = make_scorer(recall_score, pos_label=0, average='micro'),\n",
        "           n_jobs=-1,cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcgDvuLRfwsE"
      },
      "source": [
        "\n",
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loZEVp8g6q9O"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TE6Xgvif1ek"
      },
      "source": [
        "Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf6qYXV06q9O"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL2y9Zpgf4ZK"
      },
      "source": [
        "Parameters for best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK7kFD5O6q9O"
      },
      "source": [
        "grid_search_pipelines[best_model].best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeB08Md3f60p"
      },
      "source": [
        "Define the best clf pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuA9mpyk6q9P"
      },
      "source": [
        "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
        "pipeline_clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN0aj0iv6q9P"
      },
      "source": [
        "## Assess feature importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN-blGZb6q9P"
      },
      "source": [
        "# after data cleaning and feat engine, the feature space changes\n",
        "columns_after_data_cleaning_feat_eng = (PipelineDataCleaningAndFeatureEngineering()\n",
        "                                        .fit_transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "          'Attribute': columns_after_data_cleaning_feat_eng,\n",
        "          'Importance': pipeline_clf['model'].feature_importances_})\n",
        "  .sort_values(by='Importance', ascending=False)\n",
        "  )\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Attribute'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar',x='Attribute',y='Importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7fjgzReFYeM"
      },
      "source": [
        "## Evaluate Classifier on Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPeKtw3A59C3"
      },
      "source": [
        "ClfPerformanceTrainTestSet(X_train, y_train ,X_test, y_test,\n",
        "                        pipeline_clf,\n",
        "                        LabelsMap=labels_map )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBtppR73G1Yx"
      },
      "source": [
        "# Push files to the repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShuJ5tYUC06o"
      },
      "source": [
        "We will generate the following files\n",
        "\n",
        "* Train set\n",
        "* Test set\n",
        "* Modeling pipeline\n",
        "* label map\n",
        "* features importance plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vBpPvnaG5Mb"
      },
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "version = 'v1'\n",
        "file_path = f'outputs/ml_pipeline/predict_tenure/{version}'\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TvoMsi3DNw1"
      },
      "source": [
        "## Train Set : features and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJHmwyqgDOr1"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh6w6R7tDOvM"
      },
      "source": [
        "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB6pjmAcDOym"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ93HN6cDPBN"
      },
      "source": [
        "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVbS3OnRDYtJ"
      },
      "source": [
        "## Test Set: features and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbgF38n1DaPp"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9lM0xDvDaVZ"
      },
      "source": [
        "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jz66iMaDacI"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weYaJ4UxDake"
      },
      "source": [
        "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-XpkYAPFncu"
      },
      "source": [
        "## Modelling pipeline (that includes Data Cleaning and Feat Eng pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLmFFWF6RGo6"
      },
      "source": [
        "ML pipeline for predicting tenure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkr4rcrHDnn"
      },
      "source": [
        "pipeline_clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrZPif2aHdyO"
      },
      "source": [
        "joblib.dump(value=pipeline_clf ,\n",
        "            filename=f\"{file_path}/clf_pipeline.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUCrXGvUFpeB"
      },
      "source": [
        "## Dictionary mapping target levels to bins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFkAKp0eRMYM"
      },
      "source": [
        "Map for converting numerical variable to categorical variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6HfkzarHHbW"
      },
      "source": [
        "labels_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPEpdAgPHQaL"
      },
      "source": [
        "joblib.dump(value=labels_map ,\n",
        "            filename=f\"{file_path}/labels_map.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTJlYRC5Q2wJ"
      },
      "source": [
        "## Feature importance plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SfLH05-Q2D8"
      },
      "source": [
        "df_feature_importance.plot(kind='bar', x='Attribute', y='Importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Hc2H3dQ74Z"
      },
      "source": [
        "df_feature_importance.plot(kind='bar',x='Attribute',y='Importance')\n",
        "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "257gMsNhiuM3"
      },
      "source": [
        "## **Push** generated/new files from this Session to GitHub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qwo5rjVFsnL"
      },
      "source": [
        "Now you can push the files to the GitHub repo!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUla5863TKyk"
      },
      "source": [
        "* Git status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzjZgWV-TMOB"
      },
      "source": [
        "! git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH_xeleqiuM4"
      },
      "source": [
        "* Git commit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpFefbLXiuM4"
      },
      "source": [
        "CommitMsg = \"added-files-predict-tenure\"\n",
        "! git add .\n",
        "! git commit -m {CommitMsg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msFKrJ6fiuM5"
      },
      "source": [
        "* Git Push"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxYGf_yiuM5"
      },
      "source": [
        "! git push origin main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh0SKfv_s-3V"
      },
      "source": [
        "Good job! Save the notebook in your repo.\n",
        "\n",
        "Then, terminate the session (Runtime - Manage Sessions - Terminate)"
      ]
    }
  ]
}